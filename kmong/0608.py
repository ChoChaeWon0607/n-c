from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.common.keys import Keys
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter
from openpyxl import Workbook
from bs4 import BeautifulSoup
from selenium import webdriver
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service
from kiwipiepy import Kiwi
from collections import Counter
import time
import datetime
import requests
import traceback
import re

# âœ… í‚¤ì›Œë“œ ì¶”ì¶œ í•¨ìˆ˜
def extract_keywords(reviews, top_n=10):
    kiwi = Kiwi()
    stopwords = {'ìˆ˜', 'ê²ƒ', 'ì •ë„', 'ë•Œ', 'ì´', 'ê°€', 'ì€', 'ëŠ”', 'ì„', 'ë¥¼', 'ì—', 'ì˜', 'ë¡œ'}
    tokens = []
    for text in reviews:
        for token in kiwi.tokenize(text):
            if token.tag.startswith("NN") and len(token.form) > 1 and token.form not in stopwords:
                tokens.append(token.form)
    return Counter(tokens).most_common(top_n)

# âœ… ì¥ì†Œëª… â†’ place_id ì¶”ì¶œ í•¨ìˆ˜ (XPath ê¸°ë°˜ í´ë¦­)
def get_place_id_from_name(place_name, driver):
    driver.get(f"https://map.naver.com/v5/search/{place_name}")
    wait = WebDriverWait(driver, 15)

    # ê²€ìƒ‰ ê²°ê³¼ iframe ì§„ì…
    wait.until(EC.frame_to_be_available_and_switch_to_it((By.ID, "searchIframe")))

    # ì •í™•í•œ XPathë¡œ ì²« ë²ˆì§¸ ì¥ì†Œ í´ë¦­
    xpath = '//*[@id="_pcmap_list_scroll_container"]/ul/li[1]/div[1]/div[1]/a'
    first_place = wait.until(EC.element_to_be_clickable((By.XPATH, xpath)))
    driver.execute_script("arguments[0].click();", first_place)

    # ì£¼ì†Œì°½ URL ë°˜ì˜ì„ ê¸°ë‹¤ë¦¼
    driver.switch_to.default_content()
    time.sleep(2)
    current_url = driver.current_url

    match = re.search(r'/place/(\d+)', current_url)
    if match:
        return match.group(1)
    else:
        raise Exception(f"URLì—ì„œ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {current_url}")

# âœ… ì‹¤í–‰ ì‹œì‘
place_name = input("ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•  ì¥ì†Œëª…ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()

options = webdriver.ChromeOptions()
# options.add_argument('headless')  # ëˆˆìœ¼ë¡œ í™•ì¸ ì‹œ ì£¼ì„ ìœ ì§€
options.add_argument('window-size=1920x1080')
options.add_argument("disable-gpu")

driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

now = datetime.datetime.now()
xlsx = Workbook()
list_sheet = xlsx.active
list_sheet.title = 'reviews'
list_sheet.append(['nickname', 'content', 'date', 'revisit'])

review_texts = []

try:
    # âœ… ì¥ì†Œ ID ì¶”ì¶œ
    place_id = get_place_id_from_name(place_name, driver)
    print(f"[INFO] ì¥ì†Œëª… '{place_name}' â†’ ID: {place_id}")

    # âœ… ë¦¬ë·° í˜ì´ì§€ë¡œ ì´ë™
    review_url = f'https://m.place.naver.com/restaurant/{place_id}/review/visitor?entry=ple&reviewSort=recent'
    driver.get(review_url)
    driver.implicitly_wait(30)

    for _ in range(10):
        driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)

    try:
        for _ in range(30):
            driver.find_element(By.XPATH, '//*[@id="app-root"]/div/div/div/div[6]/div[2]/div[4]/div[2]/div/a/span').click()
            time.sleep(0.4)
    except Exception:
        print('ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ì¢…ë£Œ')

    time.sleep(5)
    html = driver.page_source
    bs = BeautifulSoup(html, 'lxml')
    reviews = bs.select('li.place_apply_pui.EjjAW')

    for r in reviews:
        nickname = r.select_one('div.pui__JiVbY3 > span.pui__uslU0d')
        content = r.select_one('div.pui__vn15t2 > a')
        date_elements = r.select('div.pui__QKE5Pr > span.pui__gfuUIT > time')
        date = date_elements[0] if date_elements else 'N/A'
        revisit_span = r.select('div.pui__QKE5Pr > span.pui__gfuUIT')
        revisit = revisit_span[1] if len(revisit_span) > 1 else 'N/A'

        nickname = nickname.text if nickname else ''
        content = content.text if content else ''
        date = date.text if date else ''
        revisit = revisit.text if revisit else ''
        time.sleep(0.06)

        print(nickname, '/', content, '/', date, '/', revisit)
        list_sheet.append([nickname, content, date, revisit])
        if content:
            review_texts.append(content)
        time.sleep(0.06)

    driver.quit()

    file_name = f'naver_review_{now.strftime("%Y-%m-%d_%H-%M-%S")}.xlsx'
    xlsx.save(file_name)
    print(f"\nğŸ“ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {file_name}")
    print(f"ì‹œíŠ¸ '{list_sheet.title}'ì— ì´ {list_sheet.max_row-1}ê°œì˜ ë¦¬ë·°ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # âœ… í‚¤ì›Œë“œ ì¶œë ¥
    keywords = extract_keywords(review_texts, top_n=10)
    print("\nğŸ“Œ ë¦¬ë·° í‚¤ì›Œë“œ TOP 10")
    for word, count in keywords:
        print(f"{word}: {count}íšŒ")

except Exception as e:
    print(f"\nâŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    try:
        driver.quit()
    except:
        pass
    file_name = f'naver_review_{now.strftime("%Y-%m-%d_%H-%M-%S")}_error.xlsx'
    xlsx.save(file_name)
    print(f"âš ï¸ ì˜¤ë¥˜ ë°œìƒìœ¼ë¡œ ì„ì‹œ íŒŒì¼ ì €ì¥ë¨: {file_name}")
